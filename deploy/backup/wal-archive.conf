# PostgreSQL WAL Archiving Configuration for Fleet2
# =================================================
#
# This file contains PostgreSQL configuration parameters for enabling
# Write-Ahead Log (WAL) archiving, which is required for Point-in-Time
# Recovery (PITR).
#
# INSTALLATION:
#   1. Copy these settings to your postgresql.conf
#   2. Create the archive directory with appropriate permissions
#   3. Restart PostgreSQL
#
# DIRECTORY SETUP:
#   sudo mkdir -p /var/lib/postgresql/wal_archive
#   sudo chown postgres:postgres /var/lib/postgresql/wal_archive
#   sudo chmod 700 /var/lib/postgresql/wal_archive
#
# For S3/remote archiving, see the archive_command examples below.

# -----------------------------------------------------------------------------
# WAL Settings
# -----------------------------------------------------------------------------

# Set WAL level to replica for archiving (required for PITR)
# Options: minimal, replica, logical
wal_level = replica

# Enable WAL archiving
archive_mode = on

# Archive command - executed for each completed WAL segment
# The %p is replaced with the path to the file to archive
# The %f is replaced with the file name only
#
# Option 1: Local archive (fastest, use for same-server backup)
archive_command = 'cp %p /var/lib/postgresql/wal_archive/%f'

# Option 2: Local with compression (saves space)
# archive_command = 'gzip < %p > /var/lib/postgresql/wal_archive/%f.gz'

# Option 3: S3 archive (recommended for production)
# archive_command = 'aws s3 cp %p s3://fleet2-backups/wal-archive/%f --endpoint-url ${BACKUP_ENDPOINT:-https://s3.amazonaws.com}'

# Option 4: S3 archive with compression
# archive_command = 'gzip < %p | aws s3 cp - s3://fleet2-backups/wal-archive/%f.gz --endpoint-url ${BACKUP_ENDPOINT:-https://s3.amazonaws.com}'

# Option 5: Archive with retry on failure
# archive_command = 'for i in 1 2 3; do cp %p /var/lib/postgresql/wal_archive/%f && break || sleep 5; done'

# Option 6: Archive using pgBackRest (enterprise-grade)
# archive_command = 'pgbackrest --stanza=fleet2 archive-push %p'

# Archive timeout in seconds (0 = wait indefinitely)
archive_timeout = 300

# -----------------------------------------------------------------------------
# WAL Retention Settings
# -----------------------------------------------------------------------------

# Minimum number of WAL files to keep in pg_wal
# Increase for standby servers with potential lag
wal_keep_size = 1GB

# Maximum WAL size before forcing checkpoint
max_wal_size = 2GB

# Minimum WAL size (won't shrink below this)
min_wal_size = 1GB

# -----------------------------------------------------------------------------
# Checkpoint Settings
# -----------------------------------------------------------------------------

# How often to force a checkpoint (in seconds)
checkpoint_timeout = 10min

# Target time for checkpoint completion (as fraction of checkpoint interval)
checkpoint_completion_target = 0.9

# Log checkpoints for monitoring
log_checkpoints = on

# -----------------------------------------------------------------------------
# Recovery Target Settings (for recovery.conf.template)
# -----------------------------------------------------------------------------

# These settings are used during recovery only.
# See deploy/backup/recovery.conf.template for full recovery configuration.

# -----------------------------------------------------------------------------
# Monitoring Settings
# -----------------------------------------------------------------------------

# Log archive command output for troubleshooting
log_destination = 'stderr'

# Log archive status changes
log_statement = 'ddl'

# Track WAL statistics
track_wal_io_timing = on

# -----------------------------------------------------------------------------
# S3 Archive Script
# -----------------------------------------------------------------------------
# For S3 archiving, create /usr/local/bin/archive-wal-to-s3.sh:
#
# #!/bin/bash
# set -e
# WAL_FILE="$1"
# WAL_NAME="$2"
# BUCKET="${BACKUP_BUCKET:-fleet2-backups}"
# ENDPOINT="${BACKUP_ENDPOINT:+--endpoint-url $BACKUP_ENDPOINT}"
# TIMESTAMP=$(date +%Y/%m/%d)
#
# # Compress and upload with retry
# for attempt in 1 2 3; do
#     if gzip < "$WAL_FILE" | aws s3 cp - "s3://${BUCKET}/wal-archive/${TIMESTAMP}/${WAL_NAME}.gz" $ENDPOINT; then
#         exit 0
#     fi
#     echo "Archive attempt $attempt failed, retrying..." >&2
#     sleep $((attempt * 5))
# done
# exit 1
#
# Then use: archive_command = '/usr/local/bin/archive-wal-to-s3.sh %p %f'

# -----------------------------------------------------------------------------
# Monitoring Query
# -----------------------------------------------------------------------------
# Check archive status with:
#   SELECT * FROM pg_stat_archiver;
#
# Check current WAL position:
#   SELECT pg_current_wal_lsn(), pg_walfile_name(pg_current_wal_lsn());
#
# Check archive lag:
#   SELECT pg_wal_lsn_diff(pg_current_wal_lsn(),
#     (SELECT pg_wal_lsn_diff(pg_current_wal_lsn(),
#       CASE WHEN last_archived_wal IS NOT NULL
#         THEN pg_lsn(last_archived_wal || '000000')
#         ELSE pg_current_wal_lsn()
#       END) FROM pg_stat_archiver)) as archive_lag_bytes;
